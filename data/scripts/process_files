#!/bin/bash
set -eu

usage() {
  echo "Script must be passed at least these 3 arguments:
    -p, --pums
      directory with PUMS CSV files
    -g, --geom
      directory with shapefiles for each state and PUMA
    -o, --output
      output directory
  Optional arguments (used for testing/debugging):
    -s, --state
      only process one state/area by fips code (eg. 72 for Puerto Rico)
    -y, --year
      only process data for this year (eg. 2019)
    -k, --keep
      keep temporary files
    -v, --verbose
      write all commands to stdout"
  exit 1
}

pums_dir=
shapefile_dir=
output_dir=
single_state=
single_year=
keep_tmp=false
verbose=false

if ! options=$(getopt -o p:g:o:s:y:kv -l pums:,geom:,output:,state:,year:,keep,verbose -- "$@")
then
  usage
fi

eval set -- "$options"

while [ $# -gt 0 ]
do
  case $1 in
    -p|--pums)
      pums_dir="$2"
      shift 2;;
    -g|--geom)
      shapefile_dir="$2"
      shift 2;;
    -o|--output)
      output_dir="$2"
      shift 2;;
    -s|--state)
      single_state="$2"
      shift 2;;
    -y|--year)
      single_year="$2"
      shift 2;;
    -k|--keep)
      keep_tmp=true
      shift;;
    -v|--verbose)
      verbose=true
      shift;;
    --)
      shift
      break;;
    *)
      usage
  esac
done

if [ -z "${pums_dir}" ] || [ -z "${shapefile_dir}" ] || [ -z "${output_dir}" ]; then
  usage
fi

for dir in $pums_dir $shapefile_dir
do
  if [ ! -d "$dir" ]; then
    echo "$dir does not exist."
    exit 1;
  fi
done

if [ "$verbose" = true ]; then
  set -x
fi

source ./year
source ./fips

if [ "$single_state" != "" ]; then
  validate_single_state $single_state
  echo "Only processing state/area with FIPS code of $single_state"
fi

if [ "$single_year" != "" ]; then
  validate_year $single_year
  echo "Only processing data for year $single_year"
fi

mkdir -p $output_dir

tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)

if [ "$keep_tmp" = true ]; then
  echo "Temporary files will be retained at: $tmp_dir"
else
  echo "Temporary files will be deleted at: $tmp_dir"
fi

# Generate aggregated JSON files of counts grouped by state/PUMA from PUMS CSVs
# for each year for which data has been supplied. The CSVs are several GB each
# for the 5 year PUMS. This tranformation/aggregation is the most CPU and
# memory intensive step in the processing pipeline. Aggregating the data in
# this form lets us easily work with it from here on out once we have the
# output saved to disk (output file size is MBs instead of GBs).
processed_pums_dir=$tmp_dir/pums
mkdir -p $processed_pums_dir
echo "Processing PUMS data..."
./process_pums_files languages $pums_dir $processed_pums_dir $single_state $single_year
./process_pums_files all $pums_dir $processed_pums_dir $single_state $single_year

# Fill in GeoJSON properties for states/PUMAs with speaker counts from
# processed PUMS data
processed_geojson_dir=$tmp_dir/geojson
mkdir -p $processed_geojson_dir
echo "Processing geometries..."
./build_geojson $processed_pums_dir $shapefile_dir $processed_geojson_dir $single_state

# Generate vector tiles as .pbf (Protobuf) files in z/x/y directory format.
# This is the final output of the processing pipeline that is consumed by the
# frontend to power the map, with the output files of the previous step being
# used to bake speaker counts for each language into the metadata for each area
# (state/PUMA). This allows for the app to be completely static, performing
# aggregations on language speaker counts on the frontend as needed.
echo "Building vector tiles..."
./build_tiles $processed_geojson_dir $tmp_dir $output_dir

if [ "$keep_tmp" = true ]; then
  echo "Keeping temporary files at: $tmp_dir"
else
  echo "Deleting temporary files at: $tmp_dir"
  rm -rf $tmp_dir
fi
